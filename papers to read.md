### PPO
- http://joschu.net/docs/thesis.pdf
- https://fse.studenttheses.ub.rug.nl/25709/1/mAI_2021_BickD.pdf
- https://julien-vitay.net/course-deeprl/notes/3.6-PPO.html
- https://arxiv.org/pdf/1707.06347.pdf
- https://www.youtube.com/watch?v=cQfOQcpYRzE
- https://avandekleut.github.io/ppo/
- https://github.com/0xangelo/gym-cartpole-swingup

## Lectures
- [Introduction to Robotics](https://www.youtube.com/playlist?list=PLyqSpQzTE6M_XM9cvjLLO_Azt1FkgPhpH)

## Hardware
- Unitree - GO 1
- Force
	- SeeedStudio Grove – Round Force Sensor (FSR402) [Buy](https://robu.in/product/seeedstudio-grove-round-force-sensor-fsr402/)
	- https://probots.co.in/0-2kg-force-pressure-sensor-flexible-precision-thin-film.html
- Open soruce quadruped: Dagger
	- https://www.dagor.dev/blog/dagr-quadruped-robot
- Open soruce quadruped: Solo 8 robot
	- 

## Courses
- Deep Multi-task and Meta Learning Stanford
	- https://www.youtube.com/playlist?list=PLoROMvodv4rNjRoawgt72BBNwL2V7doGI
- From Deep Learning Foundations to Stable Diffusion
	- https://www.fast.ai/posts/part2-2023.html
- Carnegie Mellon University Deep Learning
	- https://www.youtube.com/playlist?list=PLp-0K3kfddPwgBSCbDtT6NaVOd-gIHVMW
- Applied Machine Learning (Cornell CS5785)
	- https://www.youtube.com/playlist?list=PL2UML_KCiC0UlY7iCQDSiGDMovaupqc83
- Learn Pytorch
	- https://www.learnpytorch.io/pytorch_2_intro/
- Computational Sensorimotor Learning
	- https://www.youtube.com/watch?v=wDaXGbCucsY&list=PLwNwxAG-kBxPMTIs2fKWSsf7HqL2TcC78
- Advanced Robotics
	- https://people.eecs.berkeley.edu/~pabbeel/cs287-fa19/
- https://julien-vitay.net/course-deeprl/notes/3.6-PPO.html

## Books
- Mathematics of Machine Learning https://tivadardanka.com/books/mathematics-of-machine-learning
- Artificial Intelligence: Foundations of Computational Agents https://artint.info/
- The Entangled Brain: How Perception, Cognition, and Emotion Are Woven Together 
	- https://direct.mit.edu/books/oa-monograph/5490/The-Entangled-BrainHow-Perception-Cognition-and
- Diffusion language models
	- https://sander.ai/2023/01/09/diffusion-language.html


## Others
- https://github.com/VainF/Awesome-Anything
	- A curated list of general AI methods for Anything: AnyObject, AnyGeneration, AnyModel, AnyTask, etc.
- https://franknielsen.github.io/Cards/index.html

### Talk RL Podcast
- https://www.talkrl.com/

# Groups to Follow
- Meta Robotics/AI
- UC Berkely - Sergey Levine - RAIL (Robotic AI & Learning Lab)
	- http://rail.eecs.berkeley.edu/
- UC Berkely - Jintendra Malik
	- Deepak Pathak: https://www.cs.cmu.edu/~dpathak/
	- Ashish Kumar: https://ashish-kmr.github.io/
	- Ananye Agarwal: https://anag.me/
	- Zipeng Fu: https://zipengfu.github.io/
- ETH Zurich - Prof. Davide Scaramuzza - Robotics Perception Group
	- https://rpg.ifi.uzh.ch/index.html

## Extra
- 3D/Vision
	- https://github.com/totoro97/f2-nerf
	- Robo3D: Towards Robust and Reliable 3D Perception against Corruptions
		- https://ldkong.com/Robo3D
	- DINO
		- https://github.com/facebookresearch/dinov2
	- Visual Place Recognition: A Tutorial
		- https://arxiv.org/abs/2303.03281
	- Scaling Vision Transformers to 22 Billion Parameters
		- https://arxiv.org/abs/2302.05442
- NN
	- Neural networks: from the perceptron to deep nets
		- https://arxiv.org/abs/2304.06636
- Codes
	- Whisper: https://github.com/sanchit-gandhi/whisper-jax
	- Whisper Hindi: https://huggingface.co/vasista22/whisper-hindi-large-v2
	- PPO (with Isaac GYM): https://github.com/ToruOwO/minimal-stable-PPO
	- Port of OpenAI's Whisper model in C/C++ -> https://github.com/ggerganov/whisper.cpp
	- https://github.com/nomic-ai/pyllamacpp
	- https://github.com/selenasun1618/GPT-3PO
		- Voice commands -> Whisper API transcription -> GPT-4 maps instructions to robot API
		- youtube.com/watch?v=PgT8tPChbqc
- Consistency Models
	- https://github.com/openai/consistency_models
	- A Survey on Efficient Training of Transformers
		- https://arxiv.org/abs/2302.01107
- 

#### Datasets and Simulators
- DexGraspNet: A Large-Scale Robotic Dexterous Grasp Dataset for General Objects Based on Simulation
	- https://pku-epic.github.io/DexGraspNet/
- https://isaac-orbit.github.io/
- https://github.com/NVIDIA-Omniverse/IsaacGymEnvs
- https://github.com/NVIDIA-Omniverse/OmniIsaacGymEnvs
- SparseFusion: Distilling View-conditioned Diffusion for 3D Reconstruction
	- https://sparsefusion.github.io/
- Bridge Data: https://rail-berkeley.github.io/bridgedata/
- Habitat Matterport 3D Semantics Dataset
	- https://aihabitat.org/datasets/hm3d-semantics/
- Habitat Matterport Dataset
	- https://aihabitat.org/datasets/hm3d/0002.html
- Omni3D: A Large Benchmark and Model for 3D Object Detection in the Wild
	- https://github.com/facebookresearch/omni3d
- Objaverse: A Universe of Annotated 3D Objects
	- https://huggingface.co/datasets/allenai/objaverse
	- https://arxiv.org/abs/2212.08051
- Maniskill
	- https://maniskill2.github.io/
- MetaWorld
	- https://github.com/Farama-Foundation/Metaworld
- 


### Navigation
- GNM: A General Navigation Model to Drive Any Robot
	- https://sites.google.com/view/drive-any-robot
- A System for Learning High-Speed Driving via Deep RL and Autonomous Practicing
	- https://sites.google.com/view/fastrlap/
- DD-PPO: Learning Near-Perfect PointGoal Navigators from 2.5 Billion Frames
	- https://arxiv.org/pdf/1911.00357.pdf
- VER: Scaling On-Policy RL Leads to the Emergence of Navigation in Embodied Rearrangement
	- https://arxiv.org/pdf/2210.05064.pdf
- ZSON: Zero-Shot Object-Goal Navigation using Multimodal Goal Embeddings
	- https://arxiv.org/pdf/2206.12403.pdf
- Resilient and Distributed Multi-Robot Visual SLAM: Datasets, Experiments, and Lessons Learned
	- https://arxiv.org/pdf/2304.04362.pdf
- How Does It Feel? Self-Supervised Costmap Learning for Off-Road Vehicle Traversability
	- https://mateoguaman.github.io/hdif/
- 


### RL
- Gradient Estimation Using Stochastic Computation Graphs
	- https://arxiv.org/pdf/1506.05254.pdf
- DQN
	- https://towardsdatascience.com/introduction-to-the-deadly-triad-issue-of-reinforcement-learning-53613d6d11db
- Reinforcement Learning from Multiple Sensors via Joint Representations
	- https://arxiv.org/pdf/2302.05342.pdf
- Video Prediction Models as Rewards for Reinforcement
	- https://arxiv.org/pdf/2305.14343.pdf
- VIP: Towards Universal Visual Reward and Representation
	- https://arxiv.org/pdf/2210.00030.pdf
	- [CODE](https://github.com/facebookresearch/vip)
- A Generalist Dynamics Model for Control
	- https://arxiv.org/pdf/2305.10912.pdf
- HARNESSING MIXED OFFLINE REINFORCEMENT LEARNING DATASETS VIA TRAJECTORY WEIGHTING
	- https://openreview.net/pdf?id=OhUAblg27z
- Is Conditional Generative Modeling all you need for Decision-Making?
	- https://anuragajay.github.io/decision-diffuser/
- Masked Autoencoding for Scalable and Generalizable Decision Making
	- https://arxiv.org/abs/2211.12740
- IDQL: Implicit Q-Learning as an Actor-Critic Method with Diffusion Policies
	- https://arxiv.org/abs/2304.10573
- Shaking the foundations: delusions in sequence models for interaction and control
	- https://arxiv.org/abs/2110.10819
- Sequence Model Imitation Learning with Unobserved Contexts
	- https://arxiv.org/abs/2208.02225
- Bridging RL Theory and Practice with the Effective Horizon
	- https://arxiv.org/abs/2304.09853
- Efficient Deep Reinforcement Learning Requires Regulating Overfitting
	- https://arxiv.org/pdf/2304.10466.pdf
- Affordances from Human Videos as a Versatile Representation for Robotics
	- https://robo-affordances.github.io/
- Reinforcement Learning from Passive Data via Latent Intentions
	- https://dibyaghosh.com/icvf/
	- https://arxiv.org/pdf/2304.04782.pdf
- Sim2Real Predictivity: Does Evaluation in Simulation Predict Real-World Performance?
	- https://arxiv.org/pdf/1912.06321.pdf
- Generative Agents: Interactive Simulacra of Human Behavior
	-  https://arxiv.org/abs/2304.03442
- Dreamer V3: Mastering Diverse Domains through World Models
	- https://arxiv.org/pdf/2301.04104v1.pdf
	- [CODE](https://github.com/danijar/dreamerv3)
- Cal-QL: Calibrated Offline RL Pre-Training for Efficient Online Fine-Tuning
	- https://arxiv.org/abs/2303.05479
- REWARD DESIGN WITH LANGUAGE MODELS
	- https://arxiv.org/pdf/2303.00001.pdf
- Language-Driven Representation Learning for Robotics
	- https://arxiv.org/abs/2302.12766
- Offline Q-learning on Diverse Multi-Task Data Both Scales And Generalizes
	- https://openreview.net/forum?id=4-k7kUavAj
- A Closer Look at Invalid Action Masking in Policy Gradient Algorithms
	- https://costa.sh/blog-a-closer-look-at-invalid-action-masking-in-policy-gradient-algorithms.html
- Extraneousness-Aware Imitation Learning
	- https://sites.google.com/view/eil-website/
- Bitrate-Constrained DRO: Beyond Worst Case Robustness To Unknown Group Shifts
	- https://arxiv.org/abs/2302.02931
- A Survey on Transformers in Reinforcement Learning
	- https://arxiv.org/abs/2301.03044
- LaMPP: Language Models as Probabilistic Priors for Perception and Action
	- https://arxiv.org/abs/2302.02801
- State Representation Learning for Control: An Overview
	- https://arxiv.org/pdf/1802.04181.pdf
- Learning to Reach Goals via Iterated Supervised Learning
	- https://arxiv.org/pdf/1912.06088.pdf
- Goal-Conditioned Reinforcement Learning: Problems and Solutions
	- https://arxiv.org/pdf/2201.08299.pdf
- RETHINKING GOAL-CONDITIONED SUPERVISED LEARNING AND ITS CONNECTION TO OFFLINE RL
	- https://openreview.net/pdf?id=KJztlfGPdwW
- C-LEARNING: LEARNING TO ACHIEVE GOALS VIA RECURSIVE CLASSIFICATION
	- https://arxiv.org/pdf/2011.08909.pdf
- https://www.youtube.com/watch?v=QRI4KkFfsr0
- IS CONDITIONAL GENERATIVE MODELING ALL YOU NEED FOR DECISION-MAKING?
	- https://arxiv.org/pdf/2211.15657.pdf
- Experience Replay
	- https://arxiv.org/pdf/2007.06700.pdf
- PER
	- https://danieltakeshi.github.io/2019/07/14/per/

#### Task Definitions, input information and Representation
- Sensing and Filtering: A Fresh Perspective Based on Preimages and Information Spaces
	- http://lavalle.pl/papers/Lav11.pdf
	- Person: http://lavalle.pl/ispace.html
- StructDiffusion: Language-Guided Creation of Physically-Valid Structures using Unseen Objects
	- https://structdiffusion.github.io/
- Learning One Representation to Optimize All Rewards
	- https://arxiv.org/abs/2103.07945
- Understanding the World Through Action
	- https://arxiv.org/abs/2110.12543
- Reinforcement Learning from Passive Data via Latent Intentions
	- https://dibyaghosh.com/icvf/
	- https://arxiv.org/pdf/2304.04782.pdf
- Learning a Depth Covariance Function
	- https://edexheim.github.io/depth_cov/
- ConceptFusion: Open-set Multimodal 3D Mapping
	- https://concept-fusion.github.io/
- 

### Mobile Manipulation
- M-EMBER: Tackling Long-Horizon Mobile Manipulation via Factorized Domain Transfer
- DribbleBot: Dynamic Legged Manipulation in the Wild
	- https://gmargo11.github.io/dribblebot/
- Learning Agile Soccer Skills for a Bipedal Robot with Deep Reinforcement Learning
	- https://arxiv.org/abs/2304.13653
- Deep RL at Scale: Sorting Waste in Office Buildings with a Fleet of Mobile Manipulators
	- https://rl-at-scale.github.io/
- Visual Cortex and CortexBench
	- Where are we in the search for an Artificial Visual Cortex for Embodied Intelligence?
		- https://arxiv.org/pdf/2303.18240.pdf
	- [CODE](https://github.com/facebookresearch/eai-vc/)
- Adaptive Skill Coordination for Robotic Mobile Manipulation
	- https://arxiv.org/pdf/2304.00410.pdf
- Robot Learning of Mobile Manipulation with Reachability Behavior Priors
	- https://arxiv.org/abs/2203.04051
- Legs as Manipulator: Pushing Quadrupedal Agility Beyond Locomotion
	- https://robot-skills.github.io/
- 

### Manipulation
- Visuo-Tactile Transformers for Manipulation [paper](https://arxiv.org/pdf/2210.00121.pdf)
- In-Hand Object Rotation via Rapid Motor Adaptation
	- [CODE](https://github.com/HaozhiQi/hora)
- Relational-NDF SE(3)-Equivariant Relational Rearrangement with Neural Descriptor Fields
	- https://arxiv.org/abs/2211.09786
	- [CODE](https://github.com/anthonysimeonov/relational_ndf)
- Imitating Task and Motion Planning with Visuomotor Transformers
	- https://arxiv.org/abs/2305.16309
- Behavior Retrieval: Few-Shot Imitation Learning by Querying Unlabeled Datasets
	- https://arxiv.org/abs/2304.08742
- Actionable Models: Unsupervised Offline Reinforcement Learning of Robotic Skills
	- https://arxiv.org/abs/2104.07749
- MT-Opt: Continuous Multi-Task Robotic Reinforcement Learning at Scale
	- https://arxiv.org/abs/2104.08212
- CLIPort: What and Where Pathways for Robotic Manipulation
- Perceiver-Actor: A Multi-Task Transformer for Robotic Manipulation
- CabiNet: Scaling Neural Collision Detection for Object Rearrangement with Procedural Scene Generation
	- https://cabinet-object-rearrangement.github.io/?=&linkId=100000199418439
- Generalization with Lossy Affordances: Leveraging Broad Offline Data for Learning Visuomotor Tasks
	- https://sites.google.com/view/project-flap
- ARIEL: Leveraging Prior Data to Automate Robotic Reinforcement Learning
	- https://sites.google.com/view/ariel-berkeley/
- UniPi: Learning universal policies via text-guided video generation
	- https://arxiv.org/pdf/2302.00111.pdf
	- https://ai.googleblog.com/2023/04/unipi-learning-universal-policies-via.html
- Transporter Networks: Rearranging the Visual World for Robotic Manipulation
	- https://transporternets.github.io/
- Code as Policies: Language Model Programs for Embodied Control
	- https://code-as-policies.github.io/
	- https://arxiv.org/abs/2209.07753
- Learning Fine-Grained Bimanual Manipulation with Low-Cost Hardware
	- https://tonyzhaozh.github.io/aloha/
- APartNet: Cross-Category Domain-Generalizable Object Perception and Manipulation via Generalizable and Actionable Parts
	- https://pku-epic.github.io/GAPartNet/
- AVID: Learning Multi-Stage Tasks via Pixel-Level Translation of Human Videos
	- https://sites.google.com/view/rss20avid
- Grounded Decoding: Guiding Text Generation with Grounded Models for Robot Control
	- https://grounded-decoding.github.io/
- **Do As I Can, Not As I Say: Grounding Language in Robotic Affordances**
	- https://say-can.github.io/
- VIMA: General Robot Manipulation with Multimodal Prompts
	- https://vimalabs.github.io/
- **RT-1: ROBOTICS TRANSFORMER FOR REAL-WORLD CONTROL AT SCALE**
	- https://robotics-transformer.github.io/assets/rt1.pdf
- Teach a Robot to FISH: Versatile Imitation from One Minute of Demonstrations
	- https://fast-imitation.github.io/
- Open-World Object Manipulation using Pre-Trained Vision-Language Models
	- https://robot-moo.github.io/
- ALAN : Autonomously Exploring Robotic Agents in the Real World
	- https://robo-explorer.github.io/
- 
#### Imitation Learning
- Zero-Shot Robot Manipulation from Passive Human Videos
	- https://sites.google.com/view/human-0shot-robot/
- MimicPlay: Long-Horizon Imitation Learning by Watching Human Play
	- https://mimic-play.github.io/
#### Tactile
- Dexterity from Touch: Self-Supervised Pre-Training of Tactile Representations with Robotic Play
	- https://tactile-dexterity.github.io/
	- https://arxiv.org/pdf/2303.13482.pdf
- Rotating without Seeing: Towards In-hand Dexterity through Touch
	- https://touchdexterity.github.io/
	- 

### Locomotion
- Egocentric Visual Self-Modeling for Legged Robot Locomotion
- Learning Quadrupedal Locomotion over Challenging Terrain
	- https://arxiv.org/pdf/2010.11251.pdf
- Sensorimotor road to intelligence
	- link between RL and Control Theory Reference

- RMA
	- https://ashish-kmr.github.io/rma-legged-robots/rma-locomotion-final.pdf
	- https://ashish-kmr.github.io/rma-legged-robots/rma-locomotion-supplementary.pdf
- Minimizing Energy Consumption Leads to the Emergence of Gaits in Legged Robots
	- https://arxiv.org/pdf/2111.01674.pdf
- Coupling Vision and Proprioception for Navigation of Legged Robots
	- https://arxiv.org/pdf/2112.02094.pdf
	- https://navigation-locomotion.github.io/resources/navigation-locomotion.pdf
	- [CODE](https://github.com/MarkFzp/navigation-locomotion)
- Learning Visual Locomotion with Cross-Modal Supervision
	- https://antonilo.github.io/vision_locomotion/pdf/manuscript.pdf
- Legged Locomotion in Challenging Terrains using Egocentric Vision
	- https://arxiv.org/pdf/2211.07638.pdf
- Learning Agile Soccer Skills for a Bipedal Robot with Deep Reinforcement Learning
	- https://sites.google.com/view/op3-soccer
- Egocentric Visual Self-Modeling for Legged Robot Locomotion
- Learning to Walk in Minutes Using Massively Parallel Deep Reinforcement Learning
	- https://arxiv.org/abs/2109.11978
- Learning and Adapting Agility Skills by Transferring Experience
	- https://sites.google.com/berkeley.edu/twirl
- Neural Volumetric Memory for Visual Locomotion Control
	- https://rchalyang.github.io/NVM/
- A Walk in the Park: Learning to Walk in 20 Minutes With Model-Free Reinforcement Learning
	- https://arxiv.org/pdf/2208.07860.pdf
- Walk These Ways: Tuning Robot Control for Generalization with Multiplicity of Behavior
	- https://gmargo11.github.io/walk-these-ways/
- Versatile Skill Control via Self-supervised Adversarial Imitation of Unlabeled Mixed Motions
	- https://sites.google.com/view/icra2023-cassi/home
- **Pretraining quadrupeds: a case study in RL as an engineering tool**
	- https://www.interconnects.ai/p/rl-quadrupeds
- Learning agile and dynamic motor skills for legged robots
	- https://arxiv.org/abs/1901.08652
- Learning robust perceptive locomotion for quadrupedal robots in the wild
	- https://arxiv.org/abs/2201.08117
- Learning to Walk via Deep Reinforcement Learning (2019)
	- https://arxiv.org/pdf/1812.11103.pdf
- Data Efficient Reinforcement Learning for Legged Robots
	- http://proceedings.mlr.press/v100/yang20a/yang20a.pdf

### RL for control

- Reinforcement Learning in Robotics: A Survey (2013)
	- https://www.ri.cmu.edu/pub_files/2013/7/Kober_IJRR_2013.pdf
- A survey Of learning-Based control of robotic visual servoing systems
	- sciencedirect.com/science/article/pii/S0016003221006621
- A Survey of Machine Learning Approaches to Robotic Path-Planning
	- https://home.cs.colorado.edu/~mozer/Teaching/Computational%20Modeling%20Prelim/Otte.pdf
- Safe Learning in Robotics: From Learning-Based Control to Safe Reinforcement Learning
	- https://arxiv.org/pdf/2108.06266.pdf
- Deep Reinforcement Learning for the Control of Robotic Manipulation: A Focussed Mini-Review
	- https://arxiv.org/pdf/2102.04148.pdf
- Neural network based iterative learning controller for robot manipulators
	- https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=525344
- Reinforcement Learning Tracking Control for Robotic Manipulator With Kernel-Based Dynamic Model
	- https://ieeexplore.ieee.org/document/8890006
- Continuous control actions learning and adaptation for robotic manipulation through reinforcement learning
	- https://link.springer.com/article/10.1007/s10514-022-10034-z
- Neural Networks’ Based Inverse Kinematics Solution for Serial Robot Manipulators Passing Through Singularities 
	- [paper](https://cdn.intechopen.com/pdfs/14748/InTech-Neural_networks_based_inverse_kinematics_solution_for_serial_robot_manipulators_passing_through_singularities.pdf)
- Neural network-based nonlinear tracking control of kinematically redundant robot manipulators
	- https://www.sciencedirect.com/science/article/pii/S0895717711000173
	- 


- Control Transformer: Robot Navigation in Unknown Environments through PRM-Guided Return-Conditioned Sequence Modeling
	- [paper](https://www.researchgate.net/publication/365359418_Control_Transformer_Robot_Navigation_in_Unknown_Environments_through_PRM-Guided_Return-Conditioned_Sequence_Modeling)

### Papers related to generating smooth trajectories using diffusion process
- Diffusion Policies as an Expressive Policy Class for Offline Reinforcement Learning
	- [paper](https://arxiv.org/pdf/2208.06193.pdf)
	- [github](https://github.com/Zhendong-Wang/Diffusion-Policies-for-Offline-RL)

- Diffusion Policy: Visuomotor Policy Learning via Action Diffusion
	- [paper](https://arxiv.org/pdf/2303.04137.pdf#:~:text=Diffusion%20Policy%20learns%20the%20gradient,of%20stochastic%20Langevin%20dynamics%20steps.)
	- [github](https://github.com/columbia-ai-robotics/diffusion_policy)
	- https://diffusion-policy.cs.columbia.edu/


### Papers related to using different kind of input
- nerf as input
- 3d volumetric input -> But I think this should be output not input or say by-product
- **My guess on input is leaning towards basic sensors**
	- Exteroceptive
		- RGB
		- Depth (Although stereo camera can be used but since today's cameras are good at giving depth so no problem)
			- basically if sensor is robust take it as input
			- robust -> noise free, error free in sense sometime depth sensor fail and give arbitrary output
			- So I guess Stereo would work better given more data
				- **or instead of depth - Disparity is more robust input**
		- Touch/Pressure
	- Proprioceptive
		- IMU
		- Encoders - Joint angle, velocity, acceleration
- My thoughts
	- Input -> Sensors
	- Output -> Actuators
	- In between -> should be emergent by-product instead of manually defined constraints
		- Vision
			- Simple receptors/features, objects
			- and ultimately 3D should emerge out of this -> instead of constraints
		- Locomotion
			- gaits, smoothness etc should emerge out of this
		- Planning/Reasoning -> should emerge out
	- Then what could be constraint between these
		- **self-consistency** is also good constraint
			- model should give 1 coherent story
			- if there is contradiction -> means it is signal to learn 
			- **Self/Cross-supervision or Prediction** is good way to implement this self-consistency constraint
				- We can say its **property of locality**
				- Things closer to each other are similar (both in time and space)
		- **Compression or information bottleneck**
			- **Latent** variable is one way to implement this
				- Basically reduce the dimension
				- **We can reduce dimension in both time and space**
		- **Architectures**
			- Architectures which support above 2 things

